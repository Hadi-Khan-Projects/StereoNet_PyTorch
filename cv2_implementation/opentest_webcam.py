import cv2
import time
import numpy as np

# Initialize parameters for stereo block matching
params = {'minDisparity': 0,
          'numDisparities': 112,
          'blockSize': 3,
          'P1': 0,
          'P2': 0,
          'disp12MaxDiff': 1,
          'uniquenessRatio': 15,
          'speckleWindowSize': 0,
          'speckleRange': 2,
          'preFilterCap': 0,
          'mode': cv2.STEREO_SGBM_MODE_SGBM_3WAY}

# Create a window to display results
cv2.namedWindow('Disparity', cv2.WINDOW_NORMAL)

# Function to update the stereo block matcher when a trackbar moves
def on_trackbar_change(val, param):
    params[param] = val

# Create trackbars for parameters
for param in params:
    cv2.createTrackbar(param, 'Disparity', params[param], 255, lambda val, param=param: on_trackbar_change(val, param))

# Open video capture for both webcams
# Adjust the indices if your webcams are different
left_video = cv2.VideoCapture(1) 
right_video = cv2.VideoCapture(0)

while True:
    start = time.time()

    # Read frames from both webcams
    left_ret, left_frame = left_video.read()
    right_ret, right_frame = right_video.read()

    # If frames were successfully read
    if left_ret and right_ret:
        # Convert both frames to grayscale
        left_gray = cv2.cvtColor(left_frame, cv2.COLOR_BGR2GRAY)
        right_gray = cv2.cvtColor(right_frame, cv2.COLOR_BGR2GRAY)

        # Create a stereo block matcher with current parameters
        stereo = cv2.StereoSGBM_create(
            minDisparity=params['minDisparity'],
            numDisparities=params['numDisparities'],
            blockSize=params['blockSize'],
            P1=params['P1'],
            P2=params['P2'],
            disp12MaxDiff=params['disp12MaxDiff'],
            uniquenessRatio=params['uniquenessRatio'],
            speckleWindowSize=params['speckleWindowSize'],
            speckleRange=params['speckleRange'],
            preFilterCap=params['preFilterCap'],
            mode=params['mode']
        )

        # Calculate disparity (depth map)
        disparity = stereo.compute(left_gray, right_gray).astype(np.float32) / 16.0

        # Normalize disparity to the range 0-255 for viewing
        disparity = cv2.normalize(disparity, disparity, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)

        # Display disparity
        cv2.imshow('Disparity', disparity)

        # Break loop if 'q' is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

        # Print frames per second
        print("FPS: ", 1.0 / (time.time() - start))

# When everything done, release the video capture and close windows
left_video.release()
right_video.release()
cv2.destroyAllWindows()
