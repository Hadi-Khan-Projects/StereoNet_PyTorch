hydra:
  run:
    dir: ./logging/${now:%Y-%m-%d}/${now:%H-%M-%S}/hydra

stereonet_config:
  _target_: stereonet.types.StereoNetConfig
  global_settings:
    _target_: stereonet.types.GlobalSettings
    devices:
      _target_: stereonet.types.Devices
      num: 1  # type=int, help="Number of devices to use during training"
      type: "gpu"  # type=str, help="Type of device to use during training"

  logging:
    _target_: stereonet.types.Logging
    lightning_log_root: "./logging/${now:%Y-%m-%d}/${now:%H-%M-%S}"  # type=str, help="Root path to output logs files to"

  model:
    # _target_: stereonet.types.CheckpointModel
    # model_checkpoint_path: "E:\\StereoNet_PyTorch_Refactor\\logging\\2023-04-10\\10-31-22\\lightning_logs\\version_0\\checkpoints\\epoch=25-step=822978.ckpt"
    _target_: stereonet.types.StereoNetModel
    in_channels: 1
    k_downsampling_layers: 3
    k_refinement_layers: 3
    candidate_disparities: 256

  training:
    _target_: stereonet.types.Training
    fast_dev_run: false  # type=bool, help="Whether or not to run a fast dev run of the training loop"
    random_seed: null  # type=Optional[int], help="Seed to set the torch random generator for reproducible training runs"
    deterministic: null  # type=bool, help="Whether or not to set the PyTorch Lightning Trainer to deterministic mode"
    mask: null  # type=Optional[float], help="Whether or not to compute the loss for disparities larger than the mask value"
    min_epochs: 15  # type=int, help="Number of iterations of training over the full train dataset"
    max_epochs: 25  # type=int, help="Number of iterations of training over the full train dataset"
    optimizer_partial:
      _target_: torch.optim.RMSprop
      _partial_: true
      lr: 2.54e-4  # type=float, help="Starting learning rate"
      weight_decay: 0.0001
    scheduler_partial:
      _target_: torch.optim.lr_scheduler.ExponentialLR
      _partial_: true
      gamma: 0.9
    loader:
      _target_: stereonet.types.Loader
      batch_size: 1  # type=int, help='Number of examples for data loading.'
    data:
      # - _target_: stereonet.types.SceneflowData
      #   root_path: "E:\\Sceneflow"  # type=str, help='Path to the root of the Sceneflow depth files'
      #   transforms:
      #     - name: rescale
      #     - name: center_crop
      #       properties:
      #         scale: 0.925  # type=float, help='Center crop percentage to decrease GPU memory'
      - _target_: stereonet.types.KeystoneDepthData
        root_path: "E:\\Keystone\\projects\\grail\\slowglass\\2-BBox\\annotation_results"  # type=str, help='Path to the root of the Keystone depth files'
        split_ratio: 0.85  # type=float, help='Train:Test split ratio.'
        max_size:
          - 625
          - 625
        transforms:
          - _target_: torchvision.transforms.Normalize
            mean:
              - 111.5684
              - 113.6528
              - 4.3221
              - 4.2296 
            std:
              - 61.9625
              - 62.0313
              - 10.8142
              - 9.9528
    debug:
      _target_: stereonet.types.DataDebug
      enabled: False  # type=bool, help="Whether or not to use the following debugging flags"
      limit_train_batches: 10_000  # type=int, help="Debugging, how many batches to train on"

  validation:
    _target_: stereonet.types.Validation
    loader:
      _target_: stereonet.types.Loader
      batch_size: 1  # type=int, help='Number of examples for data loading.'
    data:
      - _target_: stereonet.types.KeystoneDepthData
        root_path: "E:\\Keystone\\projects\\grail\\slowglass\\2-BBox\\annotation_results"  # type=str, help='Path to the root of the Keystone depth files'
        split_ratio: 0.9  # type=float, help='Train:Test split ratio.'
        max_size:
          - 625
          - 625
        transforms:
          - _target_: torchvision.transforms.Normalize
            mean:
              - 111.5684
              - 113.6528
              - 4.3221
              - 4.2296 
            std:
              - 61.9625
              - 62.0313
              - 10.8142
              - 9.9528